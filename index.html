<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ido Galil</title>

    <meta name="author" content="Ido Galil">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">

            <!-- Top / Bio Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                      Ido Galil
                    </p>
                    <p>
                      I'm currently a Deep Learning Researcher at Nvidia and finishing my PhD under the supervision of Prof. Ran El-Yaniv at the 
                      <a href="https://www.cs.technion.ac.il/">CS faculty</a>,
                      <a href="https://www.technion.ac.il/en">Technion</a>.
                      My research at Nvidia focuses on Neural Architecture Search (NAS) for large language models (LLMs) and generative AI models.
                      My PhD at the Technion revolves around deep neural networks' reliability and safety in computer vision (CV) and natural language processing (NLP). 
                      My thesis specifically focuses on understanding and enhancing models' uncertainty estimation performance (selective prediction, confidence calibration, and ranking) 
                      and ensuring their robustness under distribution shifts and malicious adversarial attacks.
                    </p>
                    <p style="text-align:center">
                      <a href="mailto:idogalil@campus.technion.ac.il">Email</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=eZA2cu8AAAAJ&hl">Scholar</a> &nbsp;/&nbsp;
                      <a href="https://github.com/IdoGalil">Github</a> &nbsp;/&nbsp;
                      <a href="https://linkedin.com/in/ido-galil">Linkedin</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:40%;max-width:40%">
                    <a href="data/me_2024.jpeg">
                      <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" 
                           alt="profile photo" 
                           src="data/me_2024.jpeg">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Publications Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Publications</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Papers List -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>

                <!-- Puzzle (ArXiv 2024, NVIDIA) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/puzzle_overview.png" alt="Puzzle Overview" width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">Puzzle: Distillation-Based NAS for Inference-Optimized LLMs</span>
                    <br>
                    <strong>
                      Authors: Akhiad Bercovich, Tomer Ronen, Talor Abramovich, Nir Ailon, Nave Assaf, 
                      Mohammad Dabbah, Ido Galil, Amnon Geifman, Yonatan Geifman, Izhak Golan, 
                      Netanel Haber, Ehud Karpas, Roi Koren, Itay Levy, Pavlo Molchanov, Shahar Mor, 
                      Zach Moshe, Najeeb Nabwani, Omri Puny, Ran Rubin, Itamar Schen, Ido Shahaf, 
                      Oren Tropp, Omer Ullman Argov, Ran Zilberstein, Ran El-Yaniv
                    </strong>
                    <br>
                    <em>
                      <img src="images/nvidia_logo.jpg" alt="NVIDIA" style="height:30px;vertical-align:middle;margin-right:5px;">
                      ArXiv, 2024
                    </em>
                    <br><br>
                    <p>
                      <strong>TL;DR</strong>: Puzzle accelerates LLM inference on specific hardware while preserving capabilities. 
                      Through a novel decomposed NAS approach, we optimize large models (tens of billions of parameters) under strict hardware constraints. 
                      We achieve up to 2.17× speedup with minimal performance trade-off.
                    </p>
                    <p>
                      <strong>Summary</strong>: Despite LLMs’ impressive results, they’re often bottlenecked by computational costs. 
                      Puzzle addresses this by leveraging blockwise local knowledge distillation and mixed-integer programming for 
                      hardware-specific model optimization. This approach maintains accuracy while significantly reducing inference overhead.
                    </p>
                    <p>
                      <a href="https://arxiv.org/pdf/2411.19146" target="_blank">Paper</a>
                    </p>
                  </td>
                </tr>

                <!-- Hierarchical Selective Classification (NeurIPS 2024, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/hierarchical_selective_prediction.png" 
                         alt="Hierarchical Selective Classification" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">Hierarchical Selective Classification</span>
                    <br>
                    <strong>
                      Authors: Shani Goren* · Ido Galil* · Ran El-Yaniv 
                      &nbsp; (*Equal contribution)
                    </strong>
                    <br>
                    <em>
                      <img src="images/neurips_logo.png" alt="NeurIPS" style="height:30px;vertical-align:middle;margin-right:5px;">
                      NeurIPS, 2024
                      &nbsp;&nbsp;
                      <img src="images/technion_logo.png" alt="Technion" style="height:30px;vertical-align:middle;margin-left:15px;">
                    </em>
                    <br><br>
                    <p>
                      <strong>TL;DR</strong>: We extend selective classification to a hierarchical setting, 
                      allowing models to reduce the specificity of predictions (e.g., “malignant tumor” instead of a precise subtype) when uncertain.
                    </p>
                    <p>
                      <strong>Summary</strong>: Traditional selective classification only allows a full prediction or rejection. 
                      Our Hierarchical Selective Classification (HSC) uses class hierarchies to offer partial yet valuable predictions 
                      (e.g., at a higher-level node). We propose inference rules that adjust predictions based on uncertainty, 
                      improving both selective performance and calibration.
                    </p>
                    <p>
                      <a href="https://openreview.net/pdf?id=wzof7Y66xs" target="_blank">Paper</a> / 
                      <a href="https://www.youtube.com/watch?v=59CUrqKWxnw" target="_blank">Video</a> &nbsp; 
                      <a href="https://github.com/shanigoren/Hierarchical-Selective-Classification" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

                <!-- C-OOD Benchmarking (ICLR 2023, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/degredation_graph_paper.png" 
                         alt="Degradation Graph" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">
                      A Framework for Benchmarking Class-out-of-distribution Detection and its Application to ImageNet
                    </span>
                    <br>
                    <strong>Authors: Ido Galil · Mohammed Dabbah · Ran El-Yaniv</strong>
                    <br>
                    <em>
                      <img src="images/iclr_logo.png" alt="ICLR" 
                           style="height:30px;vertical-align:middle;margin-right:5px;"> 
                      ICLR, 2023 (Top 25%)
                      &nbsp;&nbsp;
                      <img src="images/technion_logo.png" alt="Technion" style="height:30px;vertical-align:middle;margin-left:15px;">
                    </em>
                    <br><br>
                    <p>
                      <strong>TL;DR</strong>: Introduces a novel framework to benchmark class-OOD detection at multiple difficulty levels. 
                      Applied to 500+ pretrained ImageNet-1k classifiers, revealing new insights on open-set recognition.
                    </p>
                    <p>
                      <strong>Summary</strong>: Existing C-OOD benchmarks can be biased or too easy. 
                      We propose a method for creating multi-level OOD benchmarks that are not biased towards any single model or detection technique. 
                      We systematically evaluate 500+ classifiers, showing how training regimes (e.g., knowledge distillation, ViT variants) 
                      impact OOD detection performance.
                    </p>
                    <p>
                      <a href="https://openreview.net/pdf?id=Iuubb9W6Jtk" target="_blank">Paper</a> / 
                      <a href="https://www.youtube.com/watch?v=Q3XF06tcdDQ&t=1s" target="_blank">Video</a> &nbsp; 
                      <a href="https://github.com/mdabbah/COOD_benchmarking" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

                <!-- 523 ImageNet Classifiers (ICLR 2023, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/Risk-Coverage_curve comparisonv3.png" 
                         alt="Risk Coverage Curve" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">
                      What Can We Learn From the Selective Prediction and Uncertainty Estimation Performance of 523 ImageNet Classifiers?
                    </span>
                    <br>
                    <strong>Authors: Ido Galil · Mohammed Dabbah · Ran El-Yaniv</strong>
                    <br>
                    <em>
                      <img src="images/iclr_logo.png" alt="ICLR" 
                           style="height:30px;vertical-align:middle;margin-right:5px;"> 
                      ICLR, 2023
                      &nbsp;&nbsp;
                      <img src="images/technion_logo.png" alt="Technion" style="height:30px;vertical-align:middle;margin-left:15px;">
                    </em>
                    <br><br>
                    <p>
                      <strong>TL;DR</strong>: Comprehensive analysis of 523 pretrained ImageNet models for selective prediction and uncertainty estimation. 
                      Highlights training regimes (especially distillation) and architectures (ViT) that excel in calibration, ranking, and selective performance.
                    </p>
                    <p>
                      <strong>Summary</strong>: We examine metrics like AUROC, ECE, selective risk, and SAC across hundreds of models. 
                      Distillation often yields the best uncertainty estimation. A subset of ViTs consistently outperforms other architectures. 
                      Post-training calibration (temperature scaling) proves more beneficial than expected in ranking and selective risk.
                    </p>
                    <p>
                      <a href="https://openreview.net/pdf?id=p66AzKi6Xim" target="_blank">Paper</a> / 
                      <a href="https://www.youtube.com/watch?v=265cP8A80qY&t=1s" target="_blank">Video</a> &nbsp;
                      <a href="https://github.com/idogalil/benchmarking-uncertainty-estimation-performance" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

                <!-- Disrupting Deep Uncertainty (NeurIPS 2021, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/ACE_Intuition.png" 
                         alt="Disrupting Deep Uncertainty Estimation" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <span class="papertitle">
                      Disrupting Deep Uncertainty Estimation Without Harming Accuracy
                    </span>
                    <br>
                    <strong>Authors: Ido Galil · Ran El-Yaniv</strong>
                    <br>
                    <em>
                      <img src="images/neurips_logo.png" alt="NeurIPS" 
                           style="height:30px;vertical-align:middle;margin-right:5px;">
                      NeurIPS, 2021
                      &nbsp;&nbsp;
                      <img src="images/technion_logo.png" alt="Technion" style="height:30px;vertical-align:middle;margin-left:15px;">
                    </em>
                    <br><br>
                    <p>
                      <strong>TL;DR</strong>: Introduces ACE (Attack on Confidence Estimation), which disrupts a neural network’s uncertainty estimates 
                      without harming its accuracy, rendering standard selective prediction mechanisms unreliable.
                    </p>
                    <p>
                      <strong>Summary</strong>: Traditional adversarial attacks target accuracy by pushing inputs across the decision boundary. 
                      ACE selectively pushes correct instances closer to the boundary (reducing confidence) and incorrect instances farther from the boundary 
                      (increasing confidence). This makes reliance on uncertainty estimates dangerous for risk-sensitive tasks (e.g., medical applications).
                    </p>
                    <p>
                      <a href="https://papers.nips.cc/paper_files/paper/2021/file/b1b20d09041289e6c3fbb81850c5da54-Paper.pdf" target="_blank">Paper</a> / 
                      <a href="https://slideslive.com/38968191/disrupting-deep-uncertainty-estimation-without-harming-accuracy" target="_blank">Video</a> &nbsp; 
                      <a href="https://github.com/IdoGalil/ACE" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

              </tbody>
            </table>

            <!-- Teaching Section -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td>
                    <h2>Teaching</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding:20px;">
                    <p>
                      I served as a TA for the “Data Structures” course at the Technion for 3.5 years. 
                      All my tutorials and other helpful materials (in Hebrew) are available on my 
                      <a href="https://www.youtube.com/@idogalil" target="_blank">YouTube channel</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Media / Interviews Section -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td>
                    <h2>Media / Interviews</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding:20px;">
                    <p>
                      I was interviewed (in Hebrew) about my PhD research and teaching experience. 
                      You can listen to the interview on 
                      <a href="https://open.spotify.com/episode/4Xjnx09wRanVGp3781VPdR" target="_blank">Spotify</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
