<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ido Galil</title>

    <meta name="author" content="Ido Galil">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-J3W42XSHWJ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-J3W42XSHWJ');
    </script>

    <!-- Minimal JS for "Read More" toggles -->
    <script>
      function toggleSummary(id) {
        const summaryDiv = document.getElementById(id);
        if (summaryDiv.style.display === "none") {
          summaryDiv.style.display = "block";
        } else {
          summaryDiv.style.display = "none";
        }
      }
    </script>
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">

            <!-- Top / Bio Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                      Ido Galil
                    </p>
                    <p>
                      I am a Deep Learning Researcher at NVIDIA and a finishing PhD student under Prof. Ran El-Yaniv at the 
                      <a href="https://www.cs.technion.ac.il/">CS faculty</a>,
                      <a href="https://www.technion.ac.il/en">Technion</a>. 
                      My work at NVIDIA focuses on Neural Architecture Search (NAS) for large language models (LLMs) and generative AI. 
                      In my PhD research, I study deep neural networks’ reliability and safety in computer vision and natural language processing, 
                      with an emphasis on uncertainty estimation, selective prediction, and adversarial robustness.
                    </p>
                    <p style="text-align:center">
                      <a href="mailto:idogalil@campus.technion.ac.il">Email</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=eZA2cu8AAAAJ&hl">Scholar</a> &nbsp;/&nbsp;
                      <a href="https://github.com/IdoGalil">Github</a> &nbsp;/&nbsp;
                      <a href="https://linkedin.com/in/ido-galil">Linkedin</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:40%;max-width:40%">
                    <a href="data/me_2024.jpeg">
                      <img style="width:100%;max-width:100%;object-fit:cover;border-radius:50%;" 
                           alt="profile photo" 
                           src="data/me_2024.jpeg">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Publications Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Publications</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Papers List -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>

                <!-- Puzzle (ArXiv 2024, NVIDIA) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/puzzle_overview.png" alt="Puzzle Overview" width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <p class="papertitle">
                      Puzzle: Distillation-Based NAS for Inference-Optimized LLMs
                    </p>
                    <p>
                      Authors: Akhiad Bercovich, Tomer Ronen, Talor Abramovich, Nir Ailon, Nave Assaf, 
                      Mohammad Dabbah, Ido Galil, Amnon Geifman, Yonatan Geifman, Izhak Golan, 
                      Netanel Haber, Ehud Karpas, Roi Koren, Itay Levy, Pavlo Molchanov, Shahar Mor, 
                      Zach Moshe, Najeeb Nabwani, Omri Puny, Ran Rubin, Itamar Schen, Ido Shahaf, 
                      Oren Tropp, Omer Ullman Argov, Ran Zilberstein, Ran El-Yaniv
                    </p>
                    <p>
                      <em>
                        ArXiv, 2024
                        &nbsp;&nbsp;
                        <img src="images/nvidia_logo.jpg" alt="NVIDIA" style="height:30px;vertical-align:middle;margin-right:5px;">
                      </em>
                    </p>
                    <p><strong>TL;DR</strong>: Puzzle accelerates LLM inference on specific hardware by leveraging blockwise local knowledge distillation and mixed-integer programming to preserve model performance while significantly reducing inference costs.</p>
                    <a href="javascript:void(0);" onclick="toggleSummary('puzzle-summary')" style="color:blue;text-decoration:underline;">Read More</a>
                    <div id="puzzle-summary" style="display:none;margin-top:10px;">
                      <p>
                        Despite LLMs’ impressive results, they are often limited by computational costs during inference. 
                        Puzzle addresses this by optimizing large-scale models for specific hardware without sacrificing accuracy, 
                        resulting in up to 2.17× speedups.
                      </p>
                    </div>
                    <p>
                      <a href="https://arxiv.org/pdf/2411.19146" target="_blank">Paper</a>
                    </p>
                  </td>
                </tr>

                <!-- Hierarchical Selective Classification (NeurIPS 2024, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/hierarchical_selective_prediction.png" 
                         alt="Hierarchical Selective Classification" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <p class="papertitle">Hierarchical Selective Classification</p>
                    <p>
                      Authors: Shani Goren* · Ido Galil* · Ran El-Yaniv 
                      &nbsp; (*Equal contribution)
                    </p>
                    <p>
                      <em>
                        <img src="images/neurips_logo.png" alt="NeurIPS" style="height:30px;vertical-align:middle;margin-right:5px;">
                        NeurIPS, 2024
                        &nbsp;&nbsp;
                        <img src="images/technion_logo.png" alt="Technion" style="height:30px;vertical-align:middle;margin-left:15px;">
                      </em>
                    </p>
                    <p><strong>TL;DR</strong>: We extend selective classification to a hierarchical setting, allowing models to reduce the specificity of predictions when uncertain.</p>
                    <a href="javascript:void(0);" onclick="toggleSummary('hsc-summary')" style="color:blue;text-decoration:underline;">Read More</a>
                    <div id="hsc-summary" style="display:none;margin-top:10px;">
                      <p>
                        Traditional selective classification only allows a full prediction or refusal. 
                        Our method uses class hierarchies to offer partial but valuable predictions (e.g., “malignant tumor” without specifying the subtype), improving calibration and risk-coverage trade-offs.
                      </p>
                    </div>
                    <p>
                      <a href="https://openreview.net/pdf?id=wzof7Y66xs" target="_blank">Paper</a> / 
                      <a href="https://www.youtube.com/watch?v=59CUrqKWxnw" target="_blank">Video</a> / 
                      <a href="https://github.com/shanigoren/Hierarchical-Selective-Classification" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

                <!-- C-OOD Benchmarking (ICLR 2023, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/degredation_graph_paper.png" 
                         alt="Degradation Graph" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <p class="papertitle">
                      A Framework for Benchmarking Class-out-of-distribution Detection and its Application to ImageNet
                    </p>
                    <p>
                      Authors: <span>Ido Galil</span> · <span>Mohammed Dabbah*</span> · <span>Ran El-Yaniv</span>
                      &nbsp; (*Equal contribution)
                    </p>
                    <p>
                      <em>
                        <img src="images/iclr_logo.png" alt="ICLR" 
                             style="height:30px;vertical-align:middle;margin-right:5px;"> 
                        ICLR, 2023 (Top 25%)
                        &nbsp;&nbsp;
                        <img src="images/technion_logo.png" alt="Technion" style="height:30px;vertical-align:middle;margin-left:15px;">
                      </em>
                    </p>
                    <p><strong>TL;DR</strong>: Introduces a new approach to generate multi-level C-OOD benchmarks for ImageNet classifiers, applied to 500+ models to reveal novel insights in open-set recognition.</p>
                    <a href="javascript:void(0);" onclick="toggleSummary('cood-summary')" style="color:blue;text-decoration:underline;">Read More</a>
                    <div id="cood-summary" style="display:none;margin-top:10px;">
                      <p>
                        Existing OOD benchmarks can be too easy or biased toward a particular model. 
                        Our framework systematically evaluates different detectors across multiple difficulty levels, uncovering how training regimes, architecture choices, and other factors influence performance.
                      </p>
                    </div>
                    <p>
                      <a href="https://openreview.net/pdf?id=Iuubb9W6Jtk" target="_blank">Paper</a> / 
                      <a href="https://www.youtube.com/watch?v=Q3XF06tcdDQ&t=1s" target="_blank">Video</a> / 
                      <a href="https://github.com/mdabbah/COOD_benchmarking" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

                <!-- 523 ImageNet Classifiers (ICLR 2023, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/Risk-Coverage_curve comparisonv3.png" 
                         alt="Risk Coverage Curve" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <p class="papertitle">
                      What Can We Learn From the Selective Prediction and Uncertainty Estimation Performance of 523 ImageNet Classifiers?
                    </p>
                    <p>
                      Authors: Ido Galil · Mohammed Dabbah · Ran El-Yaniv
                    </p>
                    <p>
                      <em>
                        <img src="images/iclr_logo.png" alt="ICLR" 
                             style="height:30px;vertical-align:middle;margin-right:5px;"> 
                        ICLR, 2023
                        &nbsp;&nbsp;
                        <img src="images/technion_logo.png" alt="Technion" style="height:30px;vertical-align:middle;margin-left:15px;">
                      </em>
                    </p>
                    <p><strong>TL;DR</strong>: Extensive study on selective prediction and uncertainty estimation across 523 ImageNet models, highlighting that distillation and certain training regimes yield superior calibration and ranking.</p>
                    <a href="javascript:void(0);" onclick="toggleSummary('imagenet523-summary')" style="color:blue;text-decoration:underline;">Read More</a>
                    <div id="imagenet523-summary" style="display:none;margin-top:10px;">
                      <p>
                        Metrics such as AUROC, ECE, selective risk, and SAC show that knowledge distillation significantly improves uncertainty estimation. 
                        A subset of ViTs outperforms other architectures, and temperature scaling benefits both calibration and ranking performance more than previously realized.
                      </p>
                    </div>
                    <p>
                      <a href="https://openreview.net/pdf?id=p66AzKi6Xim" target="_blank">Paper</a> / 
                      <a href="https://www.youtube.com/watch?v=265cP8A80qY&t=1s" target="_blank">Video</a> / 
                      <a href="https://github.com/idogalil/benchmarking-uncertainty-estimation-performance" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

                <!-- Disrupting Deep Uncertainty (NeurIPS 2021, Technion) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/ACE_Intuition.png" 
                         alt="Disrupting Deep Uncertainty Estimation" 
                         width="100%">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <p class="papertitle">
                      Disrupting Deep Uncertainty Estimation Without Harming Accuracy
                    </p>
                    <p>
                      Authors: Ido Galil · Ran El-Yaniv
                    </p>
                    <p>
                      <em>
                        <img src="images/neurips_logo.png" alt="NeurIPS" 
                             style="height:30px;vertical-align:middle;margin-right:5px;">
                        NeurIPS, 2021
                        &nbsp;&nbsp;
                        <img src="images/technion_logo.png" alt="Technion" 
                             style="height:30px;vertical-align:middle;margin-left:15px;">
                      </em>
                    </p>
                    <p><strong>TL;DR</strong>: ACE (Attack on Confidence Estimation) disrupts a neural network’s uncertainty estimations without affecting its accuracy, making standard selective mechanisms unreliable.</p>
                    <a href="javascript:void(0);" onclick="toggleSummary('ace-summary')" style="color:blue;text-decoration:underline;">Read More</a>
                    <div id="ace-summary" style="display:none;margin-top:10px;">
                      <p>
                        Traditional adversarial attacks cross decision boundaries to harm accuracy. 
                        ACE selectively increases or decreases confidence for correct/incorrect predictions without crossing boundaries, 
                        rendering uncertainty estimates dangerous in sensitive scenarios.
                      </p>
                    </div>
                    <p>
                      <a href="https://papers.nips.cc/paper_files/paper/2021/file/b1b20d09041289e6c3fbb81850c5da54-Paper.pdf" target="_blank">Paper</a> / 
                      <a href="https://slideslive.com/38968191/disrupting-deep-uncertainty-estimation-without-harming-accuracy" target="_blank">Video</a> / 
                      <a href="https://github.com/IdoGalil/ACE" target="_blank">Code</a>
                    </p>
                  </td>
                </tr>

              </tbody>
            </table>

            <!-- Teaching Section -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td>
                    <h2>Teaching</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding:20px;">
                    <p>
                      I served as a TA for the “Data Structures” course at the Technion for 3.5 years. 
                      All my tutorials and other helpful materials (in Hebrew) are available on my 
                      <a href="https://www.youtube.com/@idogalil" target="_blank">YouTube channel</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Media / Interviews Section -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td>
                    <h2>Media / Interviews</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding:20px;">
                    <p>
                      I was interviewed (in Hebrew) about my PhD research and teaching experience. 
                      You can listen to the interview on 
                      <a href="https://open.spotify.com/episode/4Xjnx09wRanVGp3781VPdR" target="_blank">Spotify</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
